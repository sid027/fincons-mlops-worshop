{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we already have downloaded raw climate data from NOAA.\n",
    "https://www.ncdc.noaa.gov/cdo-web/\n",
    "\n",
    "Normally, this would be a much more intensive process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Read in data as pandas dataframe and display first 5 rows\n",
    "features = pd.read_csv('temps.csv')\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print('The shape of our features is:', features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding takes this:\n",
    "\n",
    "| week |\n",
    "|------|\n",
    "| Mon  |\n",
    "| Tue  |\n",
    "| Wed  |\n",
    "| Thu  |\n",
    "| Fri  |\n",
    "\n",
    "and converts it into:\n",
    "\n",
    "| Mon | Tue | Wed | Thu | Fri |\n",
    "|-----|-----|-----|-----|-----|\n",
    "| 1   | 0   | 0   | 0   | 0   |\n",
    "| 0   | 1   | 0   | 0   | 0   |\n",
    "| 0   | 0   | 1   | 0   | 0   |\n",
    "| 0   | 0   | 0   | 1   | 0   |\n",
    "| 0   | 0   | 0   | 0   | 1   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# One-hot encode categorical features\n",
    "features = pd.get_dummies(features)\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print('Shape of features after one-hot encoding:', features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['actual'])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('actual', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25,\n",
    "                                                                           random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The baseline predictions are the historical averages\n",
    "baseline_preds = test_features[:, feature_list.index('average')]\n",
    "\n",
    "# Baseline errors, and display average baseline error\n",
    "baseline_errors = abs(baseline_preds - test_labels)\n",
    "print('Average baseline error: ', round(np.mean(baseline_errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate model \n",
    "rf = RandomForestRegressor(n_estimators= 1000, random_state=42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create models with different hyperparameters to try and boost performance. The only way to find the best ones\n",
    "are to try a few and evaluate them! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_new = RandomForestRegressor(n_estimators = 100, criterion = 'mse', max_depth = None, \n",
    "                               min_samples_split = 2, min_samples_leaf = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing a Single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[5]\n",
    "\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "\n",
    "# Write graph to a png file\n",
    "graph.write_png('tree.png'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "![Decision Tree](tree.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print('The depth of this tree is:', tree.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller tree for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Limit depth of tree to 2 levels\n",
    "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3, random_state=42)\n",
    "rf_small.fit(train_features, train_labels)\n",
    "\n",
    "# Extract the small tree\n",
    "tree_small = rf_small.estimators_[5]\n",
    "\n",
    "# Save the tree as a png image\n",
    "export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "\n",
    "(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
    "\n",
    "graph.write_png('small_tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Small Decision Tree](small_tree.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotated Version of Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Annotated Decision Tree](small_tree_annotated.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Most Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# New random forest with only the two most important variables\n",
    "rf_most_important = RandomForestRegressor(n_estimators= 1000, random_state=42)\n",
    "\n",
    "# Extract the two most important features\n",
    "important_indices = [feature_list.index('temp_1'), feature_list.index('average')]\n",
    "train_important = train_features[:, important_indices]\n",
    "test_important = test_features[:, important_indices]\n",
    "\n",
    "# Train the random forest\n",
    "rf_most_important.fit(train_important, train_labels)\n",
    "\n",
    "# Make predictions and determine the error\n",
    "predictions = rf_most_important.predict(test_important)\n",
    "\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "# Display the performance metrics\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "mape = np.mean(100 * (errors / test_labels))\n",
    "accuracy = 100 - mape\n",
    "\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Import matplotlib for plotting and use magic command for Jupyter Notebooks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Dates of training values\n",
    "months = features[:, feature_list.index('month')]\n",
    "days = features[:, feature_list.index('day')]\n",
    "years = features[:, feature_list.index('year')]\n",
    "\n",
    "# List and then convert to datetime object\n",
    "dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]\n",
    "dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in dates]\n",
    "\n",
    "# Dataframe with true values and dates\n",
    "true_data = pd.DataFrame(data = {'date': dates, 'actual': labels})\n",
    "\n",
    "# Dates of predictions\n",
    "months = test_features[:, feature_list.index('month')]\n",
    "days = test_features[:, feature_list.index('day')]\n",
    "years = test_features[:, feature_list.index('year')]\n",
    "\n",
    "# Column of dates\n",
    "test_dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]\n",
    "\n",
    "# Convert to datetime objects\n",
    "test_dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in test_dates]\n",
    "\n",
    "# Dataframe with predictions and dates\n",
    "predictions_data = pd.DataFrame(data = {'date': test_dates, 'prediction': predictions}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot the actual values\n",
    "plt.plot(true_data['date'], true_data['actual'], 'b-', label = 'actual')\n",
    "\n",
    "# Plot the predicted values\n",
    "plt.plot(predictions_data['date'], predictions_data['prediction'], 'ro', label = 'prediction')\n",
    "plt.xticks(rotation = '60'); \n",
    "plt.legend()\n",
    "\n",
    "# Graph labels\n",
    "plt.xlabel('Date'); plt.ylabel('Maximum Temperature (F)'); plt.title('Actual and Predicted Values');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Make the data accessible for plotting\n",
    "true_data['temp_1'] = features[:, feature_list.index('temp_1')]\n",
    "true_data['average'] = features[:, feature_list.index('average')]\n",
    "true_data['friend'] = features[:, feature_list.index('friend')]\n",
    "\n",
    "# Plot all the data as lines\n",
    "plt.plot(true_data['date'], true_data['actual'], 'b-', label  = 'actual', alpha = 1.0)\n",
    "plt.plot(true_data['date'], true_data['temp_1'], 'y-', label  = 'temp_1', alpha = 1.0)\n",
    "plt.plot(true_data['date'], true_data['average'], 'k-', label = 'average', alpha = 0.8)\n",
    "plt.plot(true_data['date'], true_data['friend'], 'r-', label = 'friend', alpha = 0.3)\n",
    "\n",
    "# Formatting plot\n",
    "plt.legend(); plt.xticks(rotation = '60');\n",
    "\n",
    "# Lables and title\n",
    "plt.xlabel('Date'); plt.ylabel('Maximum Temperature (F)'); plt.title('Actual Max Temp and Variables');"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
